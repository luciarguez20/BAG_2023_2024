{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf14b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan todas las librerías que vamos a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize#Se cargan todas las librerías que vamos a usar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71f5049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    just had a real good moment. i missssssssss hi...\n",
       "1           is reading manga  http://plurk.com/p/mzp1e\n",
       "2    @comeagainjen http://twitpic.com/2y2lx - http:...\n",
       "3    @lapcat Need to send 'em to my accountant tomo...\n",
       "4        ADD ME ON MYSPACE!!!  myspace.com/LookThunder\n",
       "Name: message to examine, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lectura de tablas de datos con panda\n",
    "data = pd.read_csv('sentiment_tweets3.csv')\n",
    "dataset = data['message to examine']\n",
    "dataset[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740408fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "def limpiar_texto(data):\n",
    "\n",
    "    for line in range(0,(len(data)-1)): \n",
    "\n",
    "        ## Eliminación de carácteres raros, URL, hashtags, menciones y emojis. \n",
    "        # Aparecían muchos carácteres hacia el final del dataset como . Buscando como podía eliminarlo, conseguí encontrar una\n",
    "        # manera de recopilar esos puntos junto a otros caracteres como â a traves de: [^\\x20-\\x7E]. \n",
    "        new_line = re.sub(r'Ã|Â|[^\\x20-\\x7E]|ì|ë|°|ï|½|<Emoji:\\s*[^>]+>|https?://\\S+|www\\.\\S+|\\b\\S+\\.com\\S+\\b|[@#]\\w+|@|¦|¢',\"\", data[line])\n",
    "        new2 = new_line.lower()\n",
    "        tokenizer = TweetTokenizer()\n",
    "        sep = tokenizer.tokenize(new2)\n",
    "        #print(sep)\n",
    "        stopW = set(stopwords.words('english'))\n",
    "        #print(stopW)\n",
    "        \n",
    "        for lista in sep:\n",
    "            filtered_sentence = [word for word in sep if not word in stopW]\n",
    "            #print(filtered_sentence)\n",
    "            \n",
    "#        filtered_sentence = []\n",
    "#        for word in sep:\n",
    "#            if word not in stopW:\n",
    "#                filtered_sentence.append(word)\n",
    "\n",
    "            lemat = SnowballStemmer('english')\n",
    "            stems = [lemat.stem(word) for word in filtered_sentence]\n",
    "        #print(stems)\n",
    "        final_text = ' '.join(stems)\n",
    "        #print(final_text)\n",
    "        data[line] == final_text \n",
    "        \n",
    "    #print(len(data))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241516b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        just had a real good moment. i missssssssss hi...\n",
       "1               is reading manga  http://plurk.com/p/mzp1e\n",
       "2        @comeagainjen http://twitpic.com/2y2lx - http:...\n",
       "3        @lapcat Need to send 'em to my accountant tomo...\n",
       "4            ADD ME ON MYSPACE!!!  myspace.com/LookThunder\n",
       "                               ...                        \n",
       "10309    No Depression by G Herbo is my mood from now o...\n",
       "10310    What do you do when depression succumbs the br...\n",
       "10311    Ketamine Nasal Spray Shows Promise Against Dep...\n",
       "10312    dont mistake a bad day with depression! everyo...\n",
       "10313                                                    0\n",
       "Name: message to examine, Length: 10314, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_texto(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def clasificador(data):\n",
    "    labels = []\n",
    "    for line in range(0,len(data)):\n",
    "        text = TextBlob(data[line])\n",
    "        sentiment_polarity = text.sentiment.polarity\n",
    "        #print(sentiment_polarity, text)\n",
    "        \n",
    "        if -1 <= sentiment_polarity <= -0.8:\n",
    "            label = \"Hater\"\n",
    "        elif -0.8 < sentiment_polarity < 0:\n",
    "            label = \"Molesto\"\n",
    "        elif sentiment_polarity == 0:\n",
    "            label = \"Neutro\"\n",
    "        elif 0 < sentiment_polarity < 0.8:\n",
    "            label = \"Contento\"\n",
    "        elif 0.8 <= sentiment_polarity <= 1:\n",
    "            label= \"Muy feliz\"\n",
    "        labels.append(label)\n",
    "        #print(text, sentiment_polarity, label)\n",
    "#    print(labels)\n",
    "#    print(len(labels))\n",
    "#    print(len(data),len(labels))\n",
    "    data['label'] = labels\n",
    "#    data==data.assign(labels)\n",
    "    print(data[0:5])\n",
    "\n",
    "#    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5013ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75679a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
