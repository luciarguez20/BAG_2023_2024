{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70531c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan todas las librerías que vamos a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bd89e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    just had a real good moment. i missssssssss hi...\n",
       "1           is reading manga  http://plurk.com/p/mzp1e\n",
       "2    @comeagainjen http://twitpic.com/2y2lx - http:...\n",
       "3    @lapcat Need to send 'em to my accountant tomo...\n",
       "4        ADD ME ON MYSPACE!!!  myspace.com/LookThunder\n",
       "Name: message to examine, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lectura de tablas de datos con panda\n",
    "data = pd.read_csv('sentiment_tweets3.csv')\n",
    "dataset = data['message to examine']  \n",
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2767144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " need to send 'em to my accountant   . 23 or 24¯¿c possible today. nice \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m new \u001b[38;5;241m=\u001b[39m new_string\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(new)\n\u001b[1;32m----> 8\u001b[0m sep_sin \u001b[38;5;241m=\u001b[39m [seps \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sep \u001b[38;5;28;01mif\u001b[39;00m sep\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords]\n",
      "Cell \u001b[1;32mIn[111], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m new \u001b[38;5;241m=\u001b[39m new_string\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(new)\n\u001b[1;32m----> 8\u001b[0m sep_sin \u001b[38;5;241m=\u001b[39m [seps \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sep \u001b[38;5;28;01mif\u001b[39;00m sep\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "string = \"@lapcat Need to send 'em to my accountant #tomo http://www.youtube.com/watch?v=zoGfqvh2ME8 <Emoji: Person with folded hands>. 23 or 24Ã¯Â¿Â½C possible today. Nice \"\n",
    "new_string = re.sub(r'Ã|Â|â|½|<Emoji:\\s*[^>]+>|https?://\\S+|www\\.\\S+|[@#]\\w+',\"\", string)\n",
    "new = new_string.lower()\n",
    "print(new)\n",
    "\n",
    "sep_sin = [seps for i in sep if sep.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da0e2298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['need', 'send', \"'\", 'em', 'accountant', '.', '23', '24', '¯', '¿', 'c', 'possible', 'today', '.', 'nice']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "#string = \"@comeagainjen http://twitpic.com/2y2lx - HOLA http://www.youtube.com/watch?v=zoGfqvh2ME8\"\n",
    "string=\"@lapcat Need to doing send 'em to my accountant #tomo http://www.youtube.com/watch?v=zoGfqvh2ME8 <Emoji: Person with folded hands>. 23 or 24Ã¯Â¿Â½C possible today. Nice \"\n",
    "new_string = re.sub(r'Ã|Â|â|½|<Emoji:\\s*[^>]+>|https?://\\S+|www\\.\\S+|[@#]\\w+',\"\", string)\n",
    "new = new_string.lower()\n",
    "tokenizer = TweetTokenizer()\n",
    "sep = tokenizer.tokenize(new)\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "#print(stopwords)\n",
    "filtered_sentence = [word for word in sep if not word in stopwords]\n",
    "\n",
    "#filtered_sentence = []\n",
    "#\n",
    "#for word in sep:\n",
    "#    if word not in stopwords:\n",
    "#        filtered_sentence.append(word)\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2bbd18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "def limpiar_texto(data):\n",
    "    new_data=[]\n",
    "    for line in range(0,len(data)): \n",
    "        new_line = re.sub(r'Ã|Â|â|ï|½|<Emoji:\\s*[^>]+>|https?://\\S+|www\\.\\S+|[@#]\\w+',\"\", data[line])\n",
    "        new2 = new_line.lower()\n",
    "        tokenizer = TweetTokenizer()\n",
    "        sep = tokenizer.tokenize(new2)\n",
    "        new_data.append(sep)\n",
    "        stopwords = set(stopwords.words('english'))\n",
    "        #print(stopwords)\n",
    "        \n",
    "        for lista in range(0,len(new_data)):\n",
    "            filtered_sentence = [word for word in sep if not word in stopwords]\n",
    "            #print(filtered_sentence)\n",
    "        \n",
    "        \n",
    "    print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad8bfcee",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'stopwords' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m limpiar_texto(dataset)\n",
      "Cell \u001b[1;32mIn[123], line 11\u001b[0m, in \u001b[0;36mlimpiar_texto\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      9\u001b[0m sep \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(new2)\n\u001b[0;32m     10\u001b[0m new_data\u001b[38;5;241m.\u001b[39mappend(sep)\n\u001b[1;32m---> 11\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#print(stopwords)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lista \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(new_data)):\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'stopwords' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "limpiar_texto(dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f9ea51b",
   "metadata": {},
   "source": [
    "### ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26c4f6",
   "metadata": {},
   "source": [
    "### pip install textblob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
